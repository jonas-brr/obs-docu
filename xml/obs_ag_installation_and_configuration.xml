<!DOCTYPE chapter
[
  <!ENTITY % entities SYSTEM "entity-decl.ent">
    %entities;
]>
<chapter xmlns="http://docbook.org/ns/docbook"
 xmlns:xi="http://www.w3.org/2001/XInclude"
 xmlns:xlink="http://www.w3.org/1999/xlink" version="5.1"
 xml:id="obs.cha.installation_and_configuration">
 <title>Installation and Configuration</title>
 <info/>

 <sect1 xml:id="planning">
  <title>Planning</title>
  <para>For testing your own OBS instance, or for small setups, such as if you only
   want to package a few scripts into RPMS and create
   proper installation sources from them, the ready-to-use obs-server appliance
   images are the easiest way. You can download them from <link
    xlink:href="http://openbuildservice.org/download/"
    >http://openbuildservice.org/download/</link>.</para>
  <para>
   However, to use the OBS for large Linux software development with
   many packages, projects and users, consider setting up a regular installation.
   Depending on the number of users, projects, and
   architectures, you can split up the back-end
   (called partitioning) and have separate hosts for the front-end and the
   database.
  </para>
  <para>For most installations, it is OK to run everything except workers
   on one host, if it has sufficient resources.</para>
  <para>For flexibility and if you want some kind of high availability it is
   recommended to use virtualization for the different components.</para>
  <sect2 xml:id="planning-resource-planning">
   <title>Resource Planning</title>
   <para>Normally, for an small or middle-sized installation, a setup with everything
    on one host (except workers) is sufficient. You should have a separate /srv
    volume for the back-end data.  We recommend that you use XFS as file system.</para>
   <para>For each scheduler architecture, you should add 4 GB RAM and one CPU
    core. For each build distribution you should add at least 50GB disk space
    per architecture.</para>
   <para>A medium instance with about 50 users can easily run on a machine with
    16GB RAM, 4 cores and 1 TB storage. The storage, of course, depends on the size
    of your projects and how often you have new versions.</para>
   <para>For bigger installations, you can use separate networks for back-end
    communication, workers and front-end.</para>
   <para>As of May 2021, the reference installation on <emphasis role="strong"
      >build.opensuse.org</emphasis>, which has a lot of users
    and distributions, runs on a partitioned setup with:</para>
   <itemizedlist>
    <listitem>
     <para> a mysql cluster as database </para>
    </listitem>
    <listitem>
     <para> api-server: 16GB RAM, 4 cores, 50GB disk </para>
    </listitem>
    <listitem>
     <para> separate binary back-ends (scheduler, dispatcher, reposerver,
      publisher, warden) </para>
    </listitem>
    <listitem>
     <para> source server: 11 GB RAM, 4 cores, 3 TB disk.  The RAM is used mainly for
      caching. </para>
    </listitem>
    <listitem>
     <para> main back-end: 62 GB RAM (oversized), 16TB disk </para>
    </listitem>
    <listitem>
     <para> a lot of workers (see - <link
       xlink:href="https://build.opensuse.org/monitor"
       >https://build.opensuse.org/monitor</link>) </para>
    </listitem>
   </itemizedlist>
   <para>For build time and performance, the count and performance of available
    worker hosts is more important than the other parts.</para>
  </sect2>
 </sect1>
 <sect1 xml:id="simple-installation">
  <title>Simple Installation</title>
  <para>In this document, we call "simple installation" an OBS installation where all OBS services are running on the same
   machine.</para>
  <important>
   <para>It is very important that you read the <emphasis role="strong"
     >README.SETUP</emphasis> file coming with your OBS version and follow the
    instructions there, because it may provide additional, version-specific information.</para>
  </important>
  <para>Before you start the installation of the OBS, you should make sure that
   your hosts have the correct fully qualified hostname, and that DNS is working and
   can resolve all names.</para>
  <sect2 xml:id="simple-installation-backend-installation">
   <title>Back-end Installation</title>
   <para>The back-end hosts all sources and built packages. It also schedules
    the jobs. To install it, install the "obs-server" package. After installation,
    it's a good idea to check the service configuration in
    <emphasis role="strong">/usr/lib/obs/server/BSConfig.pm</emphasis>, although
    the defaults should be good enough for simple cases.</para>
   <note>
    <para>
      Read more about configuring the backend in <xref linkend="distributed-setup"/>.
    </para>
   </note>
   <para>The back-end consists of a number of systemd units (services):</para>
   <table frame="all" rowsep="1" colsep="1">
    <title>Services</title>
    <?dbhtml table-width="75%"?>
    <?dbfo table-width="75%"?>
    <?dblatex table-width="75%"?>
    <tgroup cols="3">
     <colspec colname="col_1" colwidth="98*"/>
     <colspec colname="col_2" colwidth="147*"/>
     <colspec colname="col_3" colwidth="74*"/>
     <thead>
      <row>
       <entry align="left" valign="top"> Service </entry>
       <entry align="left" valign="top"> Description </entry>
       <entry align="left" valign="top"> Remark </entry>
      </row>
     </thead>
     <tbody>
      <row>
       <entry align="left" valign="top">
        <para>obssrcserver.service</para>
       </entry>
       <entry align="left" valign="top">
        <para>Source server</para>
       </entry>
       <entry align="left" valign="top">
        <para/>
       </entry>
      </row>
      <row>
       <entry align="left" valign="top">
        <para>obsrepserver.service</para>
       </entry>
       <entry align="left" valign="top">
        <para>Repository server</para>
       </entry>
       <entry align="left" valign="top">
        <para/>
       </entry>
      </row>
      <row>
       <entry align="left" valign="top">
        <para>obsservice.service</para>
       </entry>
       <entry align="left" valign="top">
        <para>Source services server</para>
       </entry>
       <entry align="left" valign="top">
        <para/>
       </entry>
      </row>
      <row>
       <entry align="left" valign="top">
        <para>obsdodup.service</para>
       </entry>
       <entry align="left" valign="top">
        <para>Repository metadata download</para>
       </entry>
       <entry align="left" valign="top">
        <para>since 2.7</para>
       </entry>
      </row>
      <row>
       <entry align="left" valign="top">
        <para>obsdeltastore.service</para>
       </entry>
       <entry align="left" valign="top">
        <para>Delta storage</para>
       </entry>
       <entry align="left" valign="top">
        <para>since 2.7</para>
       </entry>
      </row>
      <row>
       <entry align="left" valign="top">
        <para>obsscheduler.service</para>
       </entry>
       <entry align="left" valign="top">
        <para>Scheduler</para>
       </entry>
       <entry align="left" valign="top">
        <para/>
       </entry>
      </row>
      <row>
       <entry align="left" valign="top">
        <para>obsdispatcher.service</para>
       </entry>
       <entry align="left" valign="top">
        <para>Dispatcher proxy</para>
       </entry>
       <entry align="left" valign="top">
        <para/>
       </entry>
      </row>
      <row>
       <entry align="left" valign="top">
        <para>obsservicedispatch.service</para>
       </entry>
       <entry align="left" valign="top">
        <para>Dispatcher</para>
       </entry>
       <entry align="left" valign="top">
        <para/>
       </entry>
      </row>
      <row>
       <entry align="left" valign="top">
        <para>obspublisher.service</para>
       </entry>
       <entry align="left" valign="top">
        <para>Publisher</para>
       </entry>
       <entry align="left" valign="top">
        <para/>
       </entry>
      </row>
      <row>
       <entry align="left" valign="top">
        <para>obssigner.service</para>
       </entry>
       <entry align="left" valign="top">
        <para>Signer proxy</para>
       </entry>
       <entry align="left" valign="top">
        <para/>
       </entry>
      </row>
      <row>
       <entry align="left" valign="top">
        <para>obssignd.service</para>
       </entry>
       <entry align="left" valign="top">
        <para>Signer</para>
       </entry>
       <entry align="left" valign="top">
        <para/>
       </entry>
      </row>
      <row>
       <entry align="left" valign="top">
        <para>obswarden.service</para>
       </entry>
       <entry align="left" valign="top">
        <para>Warden</para>
       </entry>
       <entry align="left" valign="top">
        <para/>
       </entry>
      </row>
      <row>
       <entry align="left" valign="top">
        <para>obsclouduploadworker.service</para>
       </entry>
       <entry align="left" valign="top">
        <para>Cloud upload worker</para>
       </entry>
       <entry align="left" valign="top">
        <para>Only needed for cloud upload feature</para>
       </entry>
      </row>
      <row>
       <entry align="left" valign="top">
        <para>obsclouduploadserver.service</para>
       </entry>
       <entry align="left" valign="top">
        <para>Cloud upload server</para>
       </entry>
       <entry align="left" valign="top">
        <para>Only needed for cloud upload feature</para>
       </entry>
      </row>
     </tbody>
    </tgroup>
   </table>
    <para>These services are controlled via <emphasis>systemctl</emphasis>.
    Basically, you can enable/disable a service to start when the system
    boot, and you can start/stop/restart it in a running system as well.
    For more information, see
    <link xlink:href="https://manpages.opensuse.org/Tumbleweed/systemd/systemctl.1.en.html#COMMANDS">the systemctl man page</link>.
    For example, to restart the repository server, do:
   </para>
   <screen>systemctl restart obsrepserver.service</screen>
   <para>When starting the various services, <emphasis>obssrcserver.service</emphasis>
    (the source server) must be started first, and <emphasis>obsrepservice.service</emphasis>
    (the repository server) second, followed by the remaining services in
    any order. When installing manually, you will need to first enable the
    services with</para>
   <screen>systemctl enable &lt;name&gt;</screen>
   <para>so they start automatically at boot. In this case, the start order
    will be enforced via the respective systemd unit files. Should you want to
    start the services manually, you will need to ensure the correct ordering
    yourself, by starting the source server first and the repository server
    second, like so:</para>
   <screen>systemctl start obssrcserver.service
systemctl start obsrepserver.service
</screen>
   <para>followed by the remaining services in any order.</para>
   <warning>
    <para>The start-up commands start services which are accessible from the
     outside. If the system is connected to an untrusted network, either block
     the ports with a firewall or do not run the commands at all.</para>
   </warning>
   <sect3 xml:id="simple-installation-backend-installation-cloud-upload-setup">
    <title>Cloud Upload Setup</title>
    <para>In order to setup the Cloud Upload feature you will need to configure the tools required per each cloud provider.
      Right now we only support the AWS Amazon Cloud (<link xlink:href="https://aws.amazon.com"/>) and Microsoft Azure
      (<link xlink:href="https://portal.azure.com"/>) as providers.
    </para>
    <para>
      Before you can start uploading images to the Amazon Web Services (AWS)
      and/or Microsoft Azure, you have to:
    </para>
      <orderedlist>
        <listitem>
          <para>Install the obs-cloud-uploader package</para>
          <screen>
zypper in obs-cloud-uploader
          </screen>
        </listitem>
        <listitem>
          <para>Start the cloud upload services</para>
          <screen>
systemctl start obsclouduploadworker.service
systemctl start obsclouduploadserver.service
          </screen>
        </listitem>
      </orderedlist>
    <para>
      At last you have to register the cloud uploader service in
      <emphasis>/usr/lib/obs/server/BSConfig.pm</emphasis>, for example, by adding
      following line:
    </para>
      <screen>
our $clouduploadserver = "http://$hostname:5452";
      </screen>
    <warning>
      <para>
        Ensure that the system time of your cloud uploader instance is correct.
        AWS is relying on the timestamps of the requests it receives.
        Having an incorrect system time will cause cloud uploads to fail.
      </para>
    </warning>
    <sect4 xml:id="simple-installation-backend-installation-cloud-upload-setup-aws">
     <title>AWS Amazon Cloud</title>
     <sect5 xml:id="simple-installation-backend-installation-cloud-upload-setup-aws-aws-authentication-workflow">
       <title>Authentication Workflow</title>
       <para>
         We are going to use the role based authentication provided by Amazon to enable the OBS instance to upload images to other user's accounts.
       </para>
       <para>
         The users will obtain an external ID (automatically created and unique) and the OBS account ID to create an Identity and Access Management (IAM) role.
         After the user created the role, he needs to provide the Amazon Resource Name (ARN) of the role to OBS. OBS will use this ARN to obtain temporary credentials,
         therefore an uploader account is necessary which we need to configure (see AWS authentication credentials setup).
         OBS will use the ARN to obtain temporary credentials for the users account to upload the appliance. The ARN and the external ID are not considered as a secret.
       </para>
       <para>
         The whole workflow is described in the <link xlink:href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-user_externalid.html">AWS documentation</link>.
       </para>
     </sect5>
     <sect5 xml:id="simple-installation-backend-installation-cloud-upload-setup-aws-aws-authentication-credential-setup">
       <title>Credentials Setup</title>
       <para>
         For uploading images to AWS, OBS is using the <link xlink:href="https://aws.amazon.com/cli">AWS CLI</link> tool.
         Before you can start uploading your images, you have to enter the AWS credentials to the
         <emphasis role="strong">/etc/obs/cloudupload/.aws/credentials</emphasis> configuration file.
         These credentials will then be used by OBS to retrieve the temporary credentials from the ARN provided by users.
         More information about IAM role base authorization can be found in the <link xlink:href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-user_externalid.html">Amazon documentation</link>).
       </para>
     </sect5>
    </sect4>
    <sect4 xml:id="simple-installation-backend-installation-cloud-upload-setup-ms-azure">
     <title>Microsoft Azure</title>
     <sect5 xml:id="simple-installation-backend-installation-cloud-upload-setup-ms-azure-ms-azure-authentication-workflow">
      <title>Authentication Workflow</title>
      <para>
       The authentication is done via Microsoft's Active Directory. The user has to create a new application and needs to
       provide those two credentials to OBS:
      </para>
       <orderedlist>
        <listitem>
         <para>Application ID</para>
         <para>The Application ID is a unique ID that represents an Active Directory Application.</para>
        </listitem>
        <listitem>
         <para>Application Key</para>
         <para>The Application Key can be generated for every application and is the password.</para>
        </listitem>
       </orderedlist>
       <para>
       OBS communicates with the REST API of Microsoft Azure to authenticate and upload images.
      </para>
     </sect5>
     <sect5 xml:id="simple-installation-backend-installation-cloud-upload-setup-ms-azure-setup">
      <title>Configuration</title>
      <para>
       The <emphasis role="strong">Application ID</emphasis> and the <emphasis role="strong">Application Key</emphasis> will be stored encrypted in
       the database. As for that, it's required to generate an SSL secret and public key that has to be stored on the server where the
       <emphasis role="strong">obs-cloud-uploader</emphasis> package has been installed.
      </para>
      <para>
       To generate that SSL certificate, execute the following commands:
      </para>
       <screen>
cd /etc/obs/cloudupload
openssl genrsa -out secret.pem
openssl rsa -in secret.pem -out _pubkey -outform PEM -pubout
       </screen>
     </sect5>
     <sect5 xml:id="simple-installation-backend-installation-cloud-upload-setup-aws-ms-azure-authentication-credential-setup">
      <title>Credentials setup</title>
      <para>
       It's important that the public key is named <emphasis role="strong">_pubkey</emphasis> and the secret key is named
       <emphasis role="strong">secret.pem</emphasis> and are kept in <emphasis role="strong">/etc/obs/cloudupload</emphasis>.
      </para>
     </sect5>
    </sect4>
   </sect3>
  </sect2>
  <sect2 xml:id="simple-installation-frontend-installation">
   <title>Front-end Installation</title>
   <para>You need to install the "obs-api" package for this and a MySQL
    server.</para>
   <sect3 xml:id="simple-installation-frontend-installation-mysql-setup">
    <title>MySQL Setup</title>
    <para>Make sure that the mysql server is started on every system reboot
     (use "insserv mysql" for permanent start). You should run
     mysql_secure_installation and follow the instructions.</para>
    <para>Create the empty production databases:</para>
    <screen># mysql -u root -p
mysql&gt; create database api_production;
mysql&gt; quit</screen>
    <para>
     Use a separate MySQL user (for example,
     <systemitem class="username">obs</systemitem>) for the &obsa; access:
    </para>
    <screen># mysql -u root -p
mysql&gt; create user 'obs'@'%' identified by 'TopSecretPassword';
mysql&gt; create user 'obs'@'localhost' identified by 'TopSecretPassword';
mysql&gt; GRANT all privileges ON api_production.*
      TO 'obs'@'%', 'obs'@'localhost';
mysql&gt; FLUSH PRIVILEGES;
mysql&gt; quit</screen>
    <para>Configure your MySQL user and password in the "production" section of
     the api config: <emphasis role="strong"
       >/srv/www/obs/api/config/database.yml</emphasis>
    </para>
    <para>Example:</para>
    <screen># MySQL (default setup).  Versions 4.1 and 5.0 are recommended.
#
# Get the fast C bindings:
#   gem install mysql
#   (on OS X: gem install mysql -- --include=/usr/local/lib)
# And be sure to use new-style password hashing:
#   http://dev.mysql.com/doc/refman/5.0/en/old-client.html

production:
  adapter: mysql2
  database: api_production
  username: obs
  password: TopSecretPassword
  encoding: utf8
  timeout: 15
  pool: 30</screen>
    <para>Now populate the database</para>
    <screen>cd /srv/www/obs/api/
sudo RAILS_ENV="production" rake db:setup
sudo RAILS_ENV="production" rake writeconfiguration
sudo chown -R wwwrun.www log tmp</screen>
    <para>Now you are done with the database setup.</para>
   </sect3>
   <sect3 xml:id="simple-installation-frontend-installation-apache-setup">
    <title>Apache Setup</title>
    <para>Now we need to configure the Web server. By default, you can reach
     the familiar web user interface and also api both on port 443 speaking
     https. Repositories can be accessed via http on port 82 (once some
     packages are built). An overview page about your OBS instance can be found
     behind <emphasis>'http://localhost'</emphasis>.</para>
    <para>The obs-api package comes with an Apache vhost file, which does not
     need to get modified when you stay with these defaults:
      <emphasis>/etc/apache2/vhosts.d/obs.conf</emphasis>
    </para>
    <para>Install the required packages via</para>
    <screen>zypper in obs-api apache2 apache2-mod_xforward rubygem-passenger-apache2 memcached</screen>
    <para>
     Add the following Apache modules in <filename>/etc/sysconfig/apache2</filename>:
    </para>
    <screen>APACHE_MODULES="... passenger rewrite proxy proxy_http xforward headers socache_shmcb"</screen>
    <para>Enable SSL in /etc/sysconfig/apache2 via</para>
    <screen>APACHE_SERVER_FLAGS="SSL"</screen>
    <para>For production systems you should order official SSL certificates.
     For testing follow the instructions to create a self signed SSL
     certificate:</para>
    <screen>mkdir /srv/obs/certs
openssl genrsa -out /srv/obs/certs/server.key 4096
openssl req -new -key /srv/obs/certs/server.key \
        -out /srv/obs/certs/server.csr
openssl x509 -req -days 365 -in /srv/obs/certs/server.csr \
        -signkey /srv/obs/certs/server.key -out /srv/obs/certs/server.crt
cat /srv/obs/certs/server.key /srv/obs/certs/server.crt \
      &gt; /srv/obs/certs/server.pem</screen>
    <para>At the time of this writing (2024), we consider the 4K RSA key
     to be a safe implementation, but you might want to check out the
     current standards by consulting (on both client and server side)
     the output of</para>
    <screen><command>man crypto-policies</command></screen>
    <para>and</para>
    <screen><command>man update-crypto-policies</command></screen>
    <para>To allow the usage of https API in Web UI code you need to trust your
     certificate as well:</para>
    <screen>cp /srv/obs/certs/server.pem /etc/ssl/certs/
c_rehash /etc/ssl/certs/</screen>
   </sect3>
   <sect3 xml:id="simple-installation-frontend-installation-api-configuration">
    <title>API Configuration</title>
    <para>Check and edit <emphasis role="strong"
       >/srv/www/obs/api/config/options.yml</emphasis>
    </para>
    <para>If you change the hostnames/ips of the API, you need to adjust
      <emphasis role="strong">frontend_host</emphasis>
     accordingly. If you want to use LDAP, you need to change the LDAP settings
     as well. Look at the <xref linkend="user-and-group-management"/> for
     details. You will find examples and more details in the <xref
      linkend="configuration-files"/>.</para>
    <para>It is strongly recommended to enable</para>
    <screen>use_xforward: true</screen>
    <para>as well here, to tell Rails to forward requests to the back-end for
     asynchronous processing. (Without this setting, the front-end will block
     while the back-end handles each request.)</para>
    <para>Afterwards, you can start the OBS API and make it permanent
     via</para>
    <screen>systemctl enable apache2
systemctl start apache2

systemctl enable obs-api-support.target
systemctl start obs-api-support.target

systemctl enable memcached.service
systemctl start memcached.service</screen>
    <para>Now you have you own empty instance running and you can do some
     online configuration steps.</para>
   </sect3>
  </sect2>
  <sect2 xml:id="simple-installation-online-configuration">
   <title>Online Configuration</title>
   <para>To customize the OBS instance you may need to configure some settings
    via the OBS API and Web user interface.</para>
   <para>First you should change the password of the Admin account, for this
    you need first login as user Admin in the Web UI with the default password
    "opensuse". Click on the Admin link (right top of the page), here you can
    change the password.</para>
   <para>
    After changing the Admin password, set up &osccmd; to use the
    Admin account for more changes. Here an example:</para>
   <screen>osc -c ~/.obsadmin_osc.rc -A https://api.testobs.org</screen>
   <para>Follow the instructions on the terminal.</para>
   <warning>
    <para>The password is stored in clear text in this file by default, so you
     need to give this file restrictive access rights, only read/write access
     for your user should be allowed. <emphasis role="strong">osc</emphasis>
     allows to store the password in other ways (in keyrings for example),
     refer to the osc documentation for this.</para>
   </warning>
   <para>Now you can check out the main configuration of the OBS:</para>
   <screen>osc -c ~/.obsadmin_osc.rc api /configuration &gt;/tmp/obs.config
cat /tmp/obs.config
&lt;configuration&gt;
  &lt;title&gt;Open Build Service&lt;/title&gt;
  &lt;description&gt;
    &amp;lt;p class="description"&amp;gt;
      The &amp;lt;a href="http://openbuildservice.org"&amp;gt; Open Build Service (OBS)&amp;lt;/a&amp;gt;
      is an open and complete distribution development platform that provides a transparent
      infrastructure for development of Linux distributions, used by openSUSE, MeeGo
      and other distributions.
      Supporting also Fedora, Debian, Ubuntu, RedHat and other Linux distributions.
    &amp;lt;/p&amp;gt;
    &amp;lt;p class="description"&amp;gt;
      The OBS is developed under the umbrella of the &amp;lt;a href="http://www.opensuse.org"&amp;gt;openSUSE project&amp;lt;
      /a&amp;gt;. Please find further informations on the &amp;lt;
      a href="http://wiki.opensuse.org/openSUSE:Build_Service"&amp;gt;openSUSE Project wiki pages&amp;lt;/a&amp;gt;.
    &amp;lt;/p&amp;gt;

    &amp;lt;p class="description"&amp;gt;
      The Open Build Service developer team is greeting you. In case you use your OBS productive
      in your facility, please do us a favor and add yourself at &amp;lt;
      a href="http://wiki.opensuse.org/openSUSE:Build_Service_installations"&amp;gt;
      this wiki page&amp;lt;/a&amp;gt;. Have fun and fast build times!
    &amp;lt;/p&amp;gt;
  &lt;/description&gt;
  &lt;name&gt;private&lt;/name&gt;
  &lt;download_on_demand&gt;on&lt;/download_on_demand&gt;
  &lt;enforce_project_keys&gt;off&lt;/enforce_project_keys&gt;
  &lt;anonymous&gt;on&lt;/anonymous&gt;
  &lt;registration&gt;allow&lt;/registration&gt;
  &lt;default_access_disabled&gt;off&lt;/default_access_disabled&gt;
  &lt;allow_user_to_create_home_project&gt;on&lt;/allow_user_to_create_home_project&gt;
  &lt;disallow_group_creation&gt;off&lt;/disallow_group_creation&gt;
  &lt;change_password&gt;on&lt;/change_password&gt;
  &lt;hide_private_options&gt;off&lt;/hide_private_options&gt;
  &lt;gravatar&gt;on&lt;/gravatar&gt;
  &lt;cleanup_empty_projects&gt;on&lt;/cleanup_empty_projects&gt;
  &lt;disable_publish_for_branches&gt;on&lt;/disable_publish_for_branches&gt;
  &lt;admin_email&gt;unconfigured@openbuildservice.org&lt;/admin_email&gt;
  &lt;unlisted_projects_filter&gt;^home:.+&lt;/unlisted_projects_filter&gt;
  &lt;unlisted_projects_filter_description&gt;home projects&lt;/unlisted_projects_filter_description&gt;
  &lt;schedulers&gt;
    &lt;arch&gt;armv7l&lt;/arch&gt;
    &lt;arch&gt;i586&lt;/arch&gt;
    &lt;arch&gt;x86_64&lt;/arch&gt;
  &lt;/schedulers&gt;
&lt;/configuration&gt;</screen>
   <important>
    <para>
     <emphasis role="strong">unlisted_projects_filter</emphasis> only admit
     Regular Expression (see RLIKE specifications of MySQL/MariaDB for more
     information) and <emphasis role="strong"
      >unlisted_projects_filter_description</emphasis> is part of the link
     shown in the project list for filtering </para>
   </important>

   <para>You should edit this file according to your preferences, then sent it
    back to the server:</para>
   <screen>osc -c ~/.obsadmin_osc.rc api /configuration -T /tmp/obs.config</screen>
   <para>If you want to use an interconnect to another OBS instance to reuse
    the build targets you can do this as Admin via the Web UI or create a
    project with a <emphasis role="strong">remoteurl</emphasis> tag (see <xref
     linkend="meta-data-project-meta-data"/>)</para>
   <screen>&lt;project name="openSUSE.org"&gt;
  &lt;title&gt;openSUSE.org Project&lt;/title&gt;
  &lt;description&gt;
 This project refers to projects hosted on the Build Service
[...]

Use openSUSE.org:openSUSE:12.3 for example to build against the
openSUSE:12.3 project as specified on the opensuse.org Build Service.
&lt;/description&gt;
  &lt;remoteurl&gt;https://api.opensuse.org/public&lt;/remoteurl&gt;
&lt;/project&gt;</screen>
   <para>You can create the project using a file with the above content with
     <emphasis role="strong">osc</emphasis> like
    this:</para>
   <screen>osc -c ~/.obsadmin_osc.rc meta prj openSUSE.org -F /tmp/openSUSE.org.meta</screen>
   <para>You also can import binary distribution, see <xref
     linkend="managing-build-targets-importing-distributions"/> for this.</para>
   <para>The OBS has a list of available distributions used for build. This
    list is displayed to user, if they are adding repositories to their
    projects. This list can be managed via the API path /distributions</para>
   <screen>osc -c ~/.obsadmin_osc.rc api /distributions &gt; /tmp/distributions.xml</screen>
   <para>Example distributions.xml file:</para>
   <screen>&lt;distributions&gt;
  &lt;distribution vendor="SUSE" version="SLE-12-SP1" id="137"&gt;
    &lt;name&gt;SLE-12-SP1&lt;/name&gt;
    &lt;project&gt;SUSE:SLE-12-SP1&lt;/project&gt;
    &lt;reponame&gt;SLE-12-SP1&lt;/reponame&gt;
    &lt;repository&gt;standard&lt;/repository&gt;
    &lt;link&gt;http://www.suse.com/&lt;/link&gt;
    &lt;icon url="https://static.opensuse.org/distributions/logos/suse-SLE-12-8.png" width="8" height="8"/&gt;
    &lt;icon url="https://static.opensuse.org/distributions/logos/suse-SLE-12-16.png" width="16" height="16"/&gt;
    &lt;architecture&gt;x86_64&lt;/architecture&gt;
  &lt;/distribution&gt;
&lt;/distributions&gt;</screen>
   <para>You can add your own distributions here and update the list on the
    server:</para>
   <screen>osc -c ~/.obsadmin_osc.rc api /distributions -T /tmp/distributions.xml</screen>
  </sect2>
 </sect1>
 <sect1 xml:id="worker-farm">
  <title>Worker Farm</title>
  <para>To not burden your OBS back-end daemons with the unpredictable load
   package builds can produce (think someone builds a monstrous package like
   LibreOffice) you should not run OBS workers on the same host as the rest of
   the back-end daemons.</para>
  <important>
   <para>You back-end need to be configured to use the correct hostnames for
    the repo and source server and the ports need to be reachable by the
    workers. Also, the IP addresses of the workers need to be allowed to connect
    the services. (look at the
     <emphasis>/usr/lib/obs/server/BSConfig.pm::ipaccess</emphasis>
    array).</para>
  </important>
  <para>You can deploy workers quite simply using the worker appliance. Or
   install a minimum system plus the obs-worker package on the hardware.</para>
  <para>Edit the <emphasis role="strong"
     >/etc/sysconfig/obs-server</emphasis> file, at least
    <emphasis role="strong">OBS_SRC_SERVER</emphasis>, <emphasis role="strong"
    >OBS_REPO_SERVERS</emphasis> and <emphasis role="strong"
    >OBS_WORKER_INSTANCES</emphasis> need to be set. More details in the <xref
    linkend="configuration-files"/>.</para>
  <para>start the worker:</para>
  <screen>systemctl enable obsworker
systemctl start obsworker</screen>
 </sect1>
 <sect1 xml:id="distributed-setup">
  <title>Distributed Setup</title>
  <para>All OBS back-end daemons can also be started on individual machines in
   your network. Also, the front-end Web server and the MySQL server can run on
   different machines. Especially for large scale OBS installations this is the
   recommended setup.</para>
  <para>A setup with partitioning is very similar to the steps of the simple
   setup. Here we are only mention the differences to the simple setup.</para>
  <note>
   <para>You need to make sure that the different machines can communicate via
    the network, it is very recommended to use a separate network for this to
    isolate it from the public part.</para>
  </note>
  <para>On all back-end hosts you need to install the obs-server package. On
   the front-end host you need to install the obs-api package.</para>
  <important>
   <para>Only one source server instance can be exist on a single OBS
    installation.</para>
  </important>
  <para>The binary back-end can be split on project level, this is called
   partitioning.</para>
  <para>On one partition following services needs to be configured and
   run:</para>
  <orderedlist>
   <listitem>
    <para> repserver </para>
   </listitem>
   <listitem>
    <para> schedulers </para>
   </listitem>
   <listitem>
    <para> dispatcher </para>
   </listitem>
   <listitem>
    <para> warden </para>
   </listitem>
   <listitem>
    <para> publisher </para>
   </listitem>
  </orderedlist>
  <para>You do not need to share any directories on File System level between
   the partitions.</para>
  <para>Here some example for partitioning:</para>
  <orderedlist>
   <listitem>
    <para> A main partition for everything not in the others (host mainbackend)
    </para>
   </listitem>
   <listitem>
    <para> A home partition for all home projects of the users (host
     homebackend) </para>
   </listitem>
   <listitem>
    <para> A release partition for released software projects (host
     releasebackend) </para>
   </listitem>
  </orderedlist>
  <para>The configuration is done in the back-end config file <emphasis
    role="strong">/usr/lib/obs/server/BSConfig.pm</emphasis>. Most parts of the
   file can be shared between the back-ends.</para>
  <para>Here the important parts of the mainbackend of out testobs.org
   installation:</para>
  <screen>[...]
my $hostname = Net::Domain::hostfqdn() || 'localhost';
# IP corresponding to hostname (only used for $ipaccess); fallback to localhost since inet_aton may fail to resolve at shutdown.
my $ip = quotemeta inet_ntoa(inet_aton($hostname) || inet_aton("localhost"));

my $frontend = 'api.testobs.org'; # FQDN of the Web UI/API server if it's not $hostname

# If defined, restrict access to the backend servers (bs_repserver, bs_srcserver, bs_service)
our $ipaccess = {
   '127\..*' =&gt; 'rw', # only the localhost can write to the backend
   "^$ip" =&gt; 'rw',    # Permit IP of FQDN
   "10.20.1.100" =&gt; 'rw',    # Permit IP of srcsrv.testobs.org
   "10.20.1.101" =&gt; 'rw',    # Permit IP of mainbackend.testobs.org
   "10.20.1.102" =&gt; 'rw',    # Permit IP of homebackend.testobs.org
   "10.20.1.103" =&gt; 'rw',    # Permit IP of releasebackend.testobs.org
   '10.20.2.*' =&gt; 'worker',  # build results can be delivered from any client in the network
};

# IP of the Web UI/API Server (only used for $ipaccess)
if ($frontend) {
  my $frontendip = quotemeta inet_ntoa(inet_aton($frontend) || inet_aton("localhost"));
  $ipaccess-&gt;{$frontendip} = 'rw' ; # in dotted.quad format
}

# also change the SLP reg files in /etc/slp.reg.d/ when you touch hostname or port
our $srcserver = "http://srcsrv.testobs.org:5352";
our $reposerver = "http://mainbackend.testobs.org:5252";
our $serviceserver = "http://service.testobs.org:5152";

# Needed if you want to use the cloud upload feature
our $clouduploadserver = "http://$hostname:5452";

#
our @reposervers = ("
    http://mainbackend.testobs.org:5252,
    http://homebackend.testobs.org:5252,
    http://releasebackend.testobs.org:5252
");

# you can use different ports for worker connections
our $workersrcserver = "http://w-srcsrv.testobs.org:5353";
our $workerreposerver = "http://w-mainbackend.testobs.org:5253";
[...]
our $partition = 'main';
#
# this defines how the projects are split. All home: projects are hosted
# on an own server in this example. Order is important.
our $partitioning = [
    'home:' =&gt; 'home',
    'release' =&gt; 'release'
    '.*'    =&gt; 'main',
];
our $partitionservers = {
    'home' =&gt; 'http://homebackend.testobs.org:5252',
    'release' =&gt; 'http://releasebackend.testobs.org:5252',
    'main' =&gt; 'http://mainbackend.testobs.org:5252',
};
[...]</screen>
  <para>On the other partition server you need to change <emphasis
    role="strong">"our $reposerver"</emphasis>, <emphasis
    role="strong">"our $workerreposerver"</emphasis> and
    <emphasis role="strong">"our
   $partition"</emphasis>.</para>
  <para>On all partition servers you need to start:</para>
  <screen>systemctl start obsrepserver.service
systemctl start obsscheduler.service
systemctl start obsdispatcher.service
systemctl start obspublisher.service
systemctl start obswarden.service</screen>
  <para>On the worker machines you should set of repo servers in the <emphasis
    role="strong">OBS_REPO_SERVERS</emphasis> variable. You can also define
   workers with a subset of the repo servers to prioritize partitions.</para>
 </sect1>
 <sect1 xml:id="monitoring">
  <title>Monitoring</title>
  <para>In this chapter you will find some general monitoring instructions for
   the Open Build Service. All examples are based on Nagios plugins, but the
   information provided should be easily adaptable for other monitoring
   solutions.</para>
  <sect2 xml:id="monitoring-endpoint-checks">
   <title>Endpoint Checks</title>
   <sect3 xml:id="monitoring-endpoint-checks-http-checks-check-if-the-http-server-responds">
    <title>HTTP Checks: Checking Whether the HTTP Server Responds</title>
    <para>This check will output a critical if the HTTP server with ip address
     172.19.19.19 (-I 172.19.19.19) listening on port 80 (-p 80) does not
     answer and output a warning if the HTTP return code is not 200. The server
     name that will be used is server (-H server) which is important if
     different virtual hosts are listening on the same port.</para>
    <screen>check_http -H server -I 172.19.19.19 -p 80 -u http://server</screen>
    <para>The same check, but this time it will check a ssl enabled HTTP
     server.</para>
    <screen>check_http -S -H server -I 172.19.19.19 -p 443 -u https://server</screen>
    <para>It is also possible to check the presence of a certain string in the
     HTTP response. In this case it will check for the string <emphasis>Source
      Service Server</emphasis>.</para>
    <screen>check_http -s "Source Service Server" -S -H server -I 172.19.19.19 -p 5152</screen>
    <para>Open Build Service HTTP endpoints that should be checked:</para>
    <orderedlist>
     <listitem>
      <para> Web Interface / API: port 443 </para>
     </listitem>
     <listitem>
      <para> Repository Server: port 82 </para>
     </listitem>
     <listitem>
      <para> Package Repository Server: port 5252 </para>
     </listitem>
     <listitem>
      <para> Source Repository Server: port 5352 </para>
     </listitem>
     <listitem>
      <para> Source Service Server: port 5152 </para>
     </listitem>
     <listitem>
      <para> Cloud Upload Server: port 5452 </para>
     </listitem>
    </orderedlist>
   </sect3>
  </sect2>
  <sect2 xml:id="monitoring-common-checks">
   <title>Common Checks</title>
   <para>This is a list of common checks that should be run on each individual
    server.</para>
   <sect3 xml:id="monitoring-common-checks-disk-space-check-for-available-disk-space">
    <title>Disk Space: Checking Available Disk Space</title>
    <para>This check will output a warning if less than 10 percent disk space
     is available (-w 10) and output a critical if less than 5 percent disk
     space are available (-c 5). It will check all file systems except file
     systems with type <emphasis>none</emphasis> (-x none).</para>
    <screen>check_disk -w 10 -c 5 -x none</screen>
   </sect3>
   <sect3 xml:id="monitoring-common-checks-memory-usage-check-for-available-memory">
    <title>Memory Usage: Checking Available Memory</title>
    <para>This check will output a warning if less than 10 percent memory is
     available (-w 10) and output a critical if less than 5 percent memory is
     available (-c 5). OS caches will be counted as free memory (-C) and it
     will check the available memory (-f). check_mem.pl is not a standard
     Nagios plugin and can be downloaded at <link
      xlink:href="https://exchange.nagios.org/"
      >https://exchange.nagios.org/</link>.</para>
    <screen>check_mem.pl -f -C -w 10 -c 5</screen>
   </sect3>
   <sect3 xml:id="monitoring-common-checks-ntp-check-date-and-time">
    <title>NTP: Checking Date and Time</title>
    <para>This check will compare the local time with the time provided by the
     NTP server pool.ntp.org (-H pool.ntp.org). It will output a warning if the
     time differs by 0.5 seconds (-w 0.5) and output a critical if the time
     differs by 1 seconds (-c 1).</para>
    <screen>check_ntp_time -H pool.ntp.org -w 0.5 -c 1</screen>
   </sect3>
   <sect3 xml:id="monitoring-common-checks-ping-check-that-the-server-is-alive">
    <title>Ping: Checking That the Server Is Alive</title>
    <para>This plugin checks if the server responds to a ping request and it
     will output a warning if the respond time exceeds 200ms or 30 percent
     package loss (-w 200.0,30%) and output a critical if the respond time
     exceeds 500ms or 60 percent package loss.</para>
    <screen>check_icmp -H server -w 200.0,30% -c 500.0,60%</screen>
   </sect3>
   <sect3 xml:id="monitoring-common-checks-load-check-the-load-on-the-server">
    <title>Load: Checking the Load on the Server</title>
    <para>This check will output a warning if the load value exceeded 7.0 in
     the last minute, 6.0 in the last 5 minutes or 5.0 in the last 15 minutes
     (-w 7.0,6.0,5.0). It will output a critical if the load value exceeded
     12.0 in the last minute, 8.0 in the last 5 minutes or 6.0 in the last 15
     minutes (-c 12.0,8.0,6.0).</para>
    <screen>check_load -w 7.0,6.0,5.0 -c 12.0,8.0,6.0</screen>
   </sect3>
   <sect3 xml:id="monitoring-common-checks-disk-health-check-the-health-of-local-hard-disks">
    <title>Disk Health: Checking the Health of Local Hard Disks</title>
    <para>This check is only relevant on physical systems with local storage
     attached to it. It will check the disk status utilizing the S.M.A.R.T
     interface and it will output a critical if any of the S.M.A.R.T values
     exceeds critical limits. check_smartmon is not a standard Nagios plugin
     and can be downloaded at <link xlink:href="https://exchange.nagios.org/"
      >https://exchange.nagios.org/</link>.</para>
    <screen>check_smartmon --drive /dev/sda --drive /dev/sdb</screen>
   </sect3>
  </sect2>
  <sect2 xml:id="monitoring-other-checks">
   <title>Other Checks</title>
   <sect3 xml:id="monitoring-other-checks-mysql-check-that-the-mysql-database-is-responding">
    <title>MySQL: Checking That the MySQL Database Is Responding</title>
    <para>This check will check that the MySQL database server is running and
     that the database <emphasis>api_production</emphasis> is available.</para>
    <screen>check_mysql -H localhost -u nagios -p xxxxxx -d api_production</screen>
    <para>MySQL Databases to check:</para>
    <orderedlist>
     <listitem>
      <para> api_production </para>
     </listitem>
     <listitem>
      <para> mysql </para>
     </listitem>
    </orderedlist>
   </sect3>
   <sect3 xml:id="monitoring-other-checks-backup-status-check-that-a-valid-backup-is-avilable">
    <title>Backup Status: Checking That a Valid Backup Is Available</title>
    <para>It is always advisable to check that the last backup run was
     successful and a recent backup is available. The check itself depends on
     the Backup solution that is used.</para>
   </sect3>
  </sect2>
 </sect1>
</chapter>
